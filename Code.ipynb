{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5078259",
      "metadata": {
        "id": "c5078259"
      },
      "outputs": [],
      "source": [
        "!module load pytorchgpu/1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d467477",
      "metadata": {
        "id": "5d467477"
      },
      "outputs": [],
      "source": [
        "!pip install \"accelerate>=0.21.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d3320b",
      "metadata": {
        "id": "e6d3320b"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade \"numpy>=1.22,<1.24\" \"tensorboard>=2.12,<2.13\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a129a472",
      "metadata": {
        "id": "a129a472"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a37bd87c",
      "metadata": {
        "id": "a37bd87c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "import pickle\n",
        "import optuna\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "TUNE = True\n",
        "\n",
        "\n",
        "USE_SAVED_PARAMS = True\n",
        "\n",
        "\n",
        "loss_type  = \"Sentiment\"\n",
        "num_shots  = 4\n",
        "n_edit     = 3\n",
        "\n",
        "steps      = 40\n",
        "alpha      = 3\n",
        "\n",
        "eps        = 100.0\n",
        "k_nn       = 10\n",
        "\n",
        "trials     = 3\n",
        "seed       = 42\n",
        "device     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "verbose    = True\n",
        "\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "param_grid = {\n",
        "    'steps': [40, 80],\n",
        "    'alpha': [3],\n",
        "}\n",
        "\n",
        "\n",
        "def load_cached_model(model_id=\"facebook/opt-30b\"):\n",
        "    global model, tok, E, V, d, pos_id, neg_id\n",
        "    cache = (\"model\",\"tok\",\"E\",\"V\",\"d\",\"pos_id\",\"neg_id\")\n",
        "    if getattr(globals().get(\"model\",None),\"name_or_path\",None)==model_id \\\n",
        "       and all(v in globals() for v in cache):\n",
        "        return model, tok, E, V, d, pos_id, neg_id\n",
        "\n",
        "    if \"model\" in globals():\n",
        "        del model\n",
        "        for v in cache[1:]:\n",
        "            globals().pop(v,None)\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "    tok = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)\n",
        "    tok.pad_token = tok.eos_token\n",
        "   ### quant\n",
        "    quant_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_use_double_quant=True\n",
        "    )\n",
        "   ### quant\n",
        "\n",
        "#     model = AutoModelForCausalLM.from_pretrained(\n",
        "#         model_id, torch_dtype=torch.float16, use_auth_token=True\n",
        "#     ).to(device).eval()\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        quantization_config=quant_config,\n",
        "        device_map=\"auto\"\n",
        "    ).eval()\n",
        "\n",
        "    model.name_or_path = model_id\n",
        "\n",
        "    E      = model.get_input_embeddings().weight\n",
        "    V, d   = E.shape\n",
        "    pos_id = tok(\"positive\", add_special_tokens=False)[\"input_ids\"][0]\n",
        "    neg_id = tok(\"negative\", add_special_tokens=False)[\"input_ids\"][0]\n",
        "    return model, tok, E, V, d, pos_id, neg_id\n",
        "\n",
        "model, tok, E, V, d, pos_id, neg_id = load_cached_model()\n",
        "\n",
        "label_word = {1:\"positive\",0:\"negative\"}\n",
        "topic_word = {0:\"world\",1:\"sports\",2:\"business\",3:\"technology\"}\n",
        "\n",
        "\n",
        "train_ds = load_dataset(\"glue\",\"sst2\",split=\"train\")\n",
        "val_ds   = load_dataset(\"glue\",\"sst2\",split=\"validation\")\n",
        "\n",
        "\n",
        "traverse_full_val = False\n",
        "\n",
        "\n",
        "if not TUNE and USE_SAVED_PARAMS:\n",
        "    if os.path.exists(\"best_params.pkl\"):\n",
        "        best = pickle.load(open(\"best_params.pkl\", \"rb\"))\n",
        "        steps = best[\"steps\"]\n",
        "        alpha = best[\"alpha\"]\n",
        "    else:\n",
        "        print(\"Warning: best_params.pkl not found, using defaults.\")\n",
        "\n",
        "\n",
        "if traverse_full_val:\n",
        "    queries = list(val_ds)\n",
        "    trials  = len(queries)\n",
        "else:\n",
        "    queries = random.sample(list(val_ds), trials)\n",
        "\n",
        "\n",
        "def build_prompt(demo_df, q_sent, q_lbl):\n",
        "    if loss_type==\"Topic\":\n",
        "        instr=\"Classify the topic of the last review. Here are several examples.\"\n",
        "        tag=\"\\nTopic:\"; labmap=topic_word\n",
        "        tgt = tok(labmap[q_lbl],add_special_tokens=False)[\"input_ids\"][0]\n",
        "    else:\n",
        "        instr=(\n",
        "          \"Analyze the sentiment of the last review and respond with \"\n",
        "          \"either positive or negative. Here are several examples.\"\n",
        "        )\n",
        "        tag=\"\\nSentiment:\"; labmap=label_word\n",
        "        tgt = pos_id if q_lbl==1 else neg_id\n",
        "\n",
        "    demos_str=\"\"; demo_sents=[]\n",
        "    for sent,lab in zip(demo_df[\"sentence\"][:num_shots],\n",
        "                        demo_df[\"label\"][:num_shots]):\n",
        "        s=sent.strip(); demo_sents.append(s)\n",
        "        demos_str+=f\"\\nReview: {s}{tag}{labmap[lab]}\"\n",
        "    q_stub=f\"\\nReview: {q_sent.strip()}{tag[:-1]}:\"\n",
        "    return f\"{instr}\\n{demos_str}{q_stub}\", demo_sents, tgt\n",
        "\n",
        "def classify_token(ids):\n",
        "    lg = model(ids.unsqueeze(0)).logits[0,-1]\n",
        "    if lg[pos_id]>lg[neg_id]:\n",
        "        p=pos_id; prob=torch.softmax(lg[[neg_id,pos_id]],0)[1].item()\n",
        "    else:\n",
        "        p=neg_id; prob=torch.softmax(lg[[neg_id,pos_id]],0)[0].item()\n",
        "    return p, prob\n",
        "\n",
        "def run_alg1_with_query(train_ds, query, trial_idx):\n",
        "    demo_df = pd.DataFrame(random.sample(list(train_ds), num_shots))\n",
        "    prompt, demo_sents, tgt_id = build_prompt(\n",
        "        demo_df, query[\"sentence\"], query[\"label\"]\n",
        "    )\n",
        "    enc = tok(prompt,\n",
        "              return_tensors=\"pt\",\n",
        "              return_offsets_mapping=True,\n",
        "              add_special_tokens=False).to(device)\n",
        "    ids  = enc.input_ids[0]\n",
        "    mask = enc.attention_mask[0]\n",
        "    offs = enc.offset_mapping[0].tolist()\n",
        "\n",
        "    spans=[]\n",
        "    for s in demo_sents:\n",
        "        cs,ce=prompt.index(s),prompt.index(s)+len(s)\n",
        "        tok_s=next(i for i,(a,b) in enumerate(offs) if a<=cs<b)\n",
        "        tok_e=next(i for i,(a,b) in enumerate(offs) if a<ce<=b)+1\n",
        "        spans.append([tok_s,tok_e,[]])\n",
        "\n",
        "    # —— Added: record label token spans for each ICE ——\n",
        "    if loss_type==\"Topic\":\n",
        "        tag=\"\\nTopic:\"; labmap=topic_word\n",
        "    else:\n",
        "        tag=\"\\nSentiment:\"; labmap=label_word\n",
        "    label_spans = []\n",
        "    for sent, lab in zip(demo_sents, demo_df[\"label\"][:num_shots]):\n",
        "        sent_idx = prompt.index(sent)\n",
        "        char_start = prompt.find(tag+labmap[lab], sent_idx+len(sent))\n",
        "        char_end = char_start + len(tag+labmap[lab])\n",
        "        tokens = [i for i,(a,b) in enumerate(offs) if b>char_start and a<char_end]\n",
        "        label_spans.append(tokens)\n",
        "\n",
        "    pred_b,prob_b=classify_token(ids)\n",
        "    base_ok=(pred_b==tgt_id)\n",
        "\n",
        "\n",
        "    pre_eps=eps/num_shots\n",
        "    delta_pre=torch.zeros_like(E[ids],requires_grad=True)\n",
        "    for _ in range(steps):\n",
        "        out=model(inputs_embeds=(E[ids]+delta_pre).unsqueeze(0),\n",
        "                  attention_mask=mask.unsqueeze(0)).logits[0,-1]\n",
        "        loss=F.cross_entropy(out.unsqueeze(0),\n",
        "                             torch.tensor([tgt_id],device=device))\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for s,e,posL in spans:\n",
        "                delta_pre[s:e]+=alpha*delta_pre.grad[s:e]\n",
        "                if delta_pre[s:e].norm()>pre_eps:\n",
        "                    delta_pre[s:e]*=pre_eps/delta_pre[s:e].norm()\n",
        "            delta_pre.grad.zero_()\n",
        "\n",
        "    for s,e,posL in spans:\n",
        "        norms=delta_pre[s:e].norm(dim=1)\n",
        "        topk =norms.topk(min(n_edit,e-s)).indices+s\n",
        "        posL.extend(topk.tolist())\n",
        "\n",
        "\n",
        "    delta=torch.zeros_like(E[ids],requires_grad=True)\n",
        "    trace=[]\n",
        "    for _ in range(steps):\n",
        "        out=model(inputs_embeds=(E[ids]+delta).unsqueeze(0),\n",
        "                  attention_mask=mask.unsqueeze(0)).logits[0,-1]\n",
        "        loss=F.cross_entropy(out.unsqueeze(0),\n",
        "                             torch.tensor([tgt_id],device=device))\n",
        "        trace.append(loss.item()); loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for _,_,posL in spans:\n",
        "                for p in posL:\n",
        "                    delta[p]+=alpha*delta.grad[p]\n",
        "            if delta.norm()>eps: delta.mul_(eps/delta.norm())\n",
        "            delta.grad.zero_()\n",
        "\n",
        "    ids_adv=ids.clone()\n",
        "    save_dict = {\n",
        "        \"demo_df\":    demo_df.to_dict(),\n",
        "        \"query\":      {\"sentence\": query[\"sentence\"], \"label\": query[\"label\"]},\n",
        "        \"spans\":      spans,\n",
        "        \"delta\":      delta.detach().cpu().numpy(),\n",
        "        \"ice\":        {},\n",
        "        \"label_spans\": label_spans\n",
        "    }\n",
        "    for idx,(s,e,posL) in enumerate(spans,1):\n",
        "        toks=[]\n",
        "        for p in posL:\n",
        "            orig=ids[p].item()\n",
        "            best_id = None\n",
        "            tgtv=E[orig]+delta[p]\n",
        "            mask_ball=(E-E[orig]).norm(dim=1)<=eps\n",
        "            cands=torch.where(mask_ball)[0]\n",
        "            if cands.numel()>0:\n",
        "                dists=(E[cands]-tgtv).norm(dim=1)\n",
        "                best_id = int(cands[dists.topk(min(k_nn,cands.numel()),\n",
        "                                              largest=False).indices[0]])\n",
        "                ids_adv[p]=best_id\n",
        "            toks.append({\n",
        "              'pos':p,\n",
        "              'orig_token':tok.convert_ids_to_tokens([orig])[0],\n",
        "              'adv_token' :tok.convert_ids_to_tokens([best_id])[0] if best_id is not None else None,\n",
        "              'orig_embedding':E[orig].detach().cpu().numpy(),\n",
        "              'adv_embedding':E[best_id].detach().cpu().numpy() if best_id is not None else None,\n",
        "              'delta':delta[p].detach().cpu().numpy()\n",
        "            })\n",
        "        save_dict[\"ice\"][f\"ICE_{idx}\"] = {\n",
        "          'pre_text':   tok.decode(ids[s:e],skip_special_tokens=True),\n",
        "          'post_text':  tok.decode(ids_adv[s:e],skip_special_tokens=True),\n",
        "          'token_info': toks\n",
        "        }\n",
        "\n",
        "\n",
        "    pred_a,prob_a = classify_token(ids_adv)\n",
        "    adv_ok        = (pred_a==tgt_id)\n",
        "    clean_acc     = float(base_ok)\n",
        "    adv_acc       = float(adv_ok)\n",
        "    drop          = clean_acc - adv_acc\n",
        "    asr           = 1.0 - (adv_acc / clean_acc) if clean_acc>0 else 0.0\n",
        "\n",
        "    print(f\"\\n=== Metrics Trial {trial_idx} ===\")\n",
        "    print(f\"  clean_acc: {clean_acc:.3f}\")\n",
        "    print(f\"  adv_acc  : {adv_acc:.3f}\")\n",
        "    print(f\"  drop     : {drop:.3f}\")\n",
        "    print(f\"  ASR      : {asr:.3f}\")\n",
        "\n",
        "    save_dict[\"metrics\"] = {\n",
        "        \"clean_acc\": clean_acc,\n",
        "        \"adv_acc\":   adv_acc,\n",
        "        \"drop\":      drop,\n",
        "        \"ASR\":       asr\n",
        "    }\n",
        "\n",
        "    os.makedirs(\"perturb_info\",exist_ok=True)\n",
        "    with open(f\"perturb_info/ice_deltas_trial_{trial_idx}.pkl\",\"wb\") as f:\n",
        "        pickle.dump(save_dict,f)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n=== Alg1 Trial {trial_idx} ===\")\n",
        "        print(\"loss trace:\",[f\"{x:.3f}\" for x in trace])\n",
        "        print(f\"Baseline    : {tok.convert_ids_to_tokens([pred_b])[0]} (p={prob_b:.2f})\",\"✓\" if base_ok else \"✗\")\n",
        "        print(f\"AfterAttack : {tok.convert_ids_to_tokens([pred_a])[0]} (p={prob_a:.2f})\",\"✓\" if adv_ok else \"✗\")\n",
        "        print(\"\\n--- ICE Replacement Details ---\")\n",
        "        for idx,(s,e,posL) in enumerate(spans,1):\n",
        "            before=tok.decode(ids[s:e],skip_special_tokens=True)\n",
        "            after =tok.decode(ids_adv[s:e],skip_special_tokens=True)\n",
        "            repl  =[(tok.convert_ids_to_tokens([ids[p]])[0],\n",
        "                     tok.convert_ids_to_tokens([ids_adv[p]])[0]) for p in posL]\n",
        "            print(f\"\\nICE {idx}:\")\n",
        "            print(\"  Before:\",before)\n",
        "            print(\"  After: \",after)\n",
        "            print(\"  Replaced tokens:\",repl)\n",
        "\n",
        "    return base_ok, adv_ok\n",
        "\n",
        "\n",
        "if TUNE:\n",
        "\n",
        "    _plateau = {\"best\": 0.0, \"count\": 0}\n",
        "    _asr_history = []\n",
        "\n",
        "    def plateau_callback(study, trial):\n",
        "        global _asr_history, _plateau\n",
        "        val = trial.value\n",
        "        _asr_history.append(val)\n",
        "\n",
        "        if val > _plateau[\"best\"] + 1e-3:\n",
        "            _plateau[\"best\"] = val\n",
        "            _plateau[\"count\"] = 0\n",
        "        else:\n",
        "            _plateau[\"count\"] += 1\n",
        "        if _plateau[\"count\"] >= 5:\n",
        "            study.stop()\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(_asr_history, marker='o')\n",
        "        plt.title('ASRup')\n",
        "        plt.xlabel('trail number')\n",
        "        plt.ylabel('(ASR)')\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('asr_progress.png')\n",
        "\n",
        "\n",
        "        try:\n",
        "            plt.show(block=False)\n",
        "            plt.pause(0.1)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "    def objective(trial):\n",
        "        global steps, alpha\n",
        "        steps = trial.suggest_categorical(\"steps\", param_grid['steps'])\n",
        "        alpha = trial.suggest_categorical(\"alpha\", param_grid['alpha'])\n",
        "\n",
        "        base_cnt = adv_cnt = 0\n",
        "        for t, query in enumerate(queries, start=1):\n",
        "            b, a = run_alg1_with_query(train_ds, query, t)\n",
        "            base_cnt += b\n",
        "            adv_cnt  += a\n",
        "\n",
        "        clean_acc = base_cnt / len(queries)\n",
        "        adv_acc   = adv_cnt  / len(queries)\n",
        "        asr       = 1.0 - (adv_acc / clean_acc) if clean_acc > 0 else 0.0\n",
        "\n",
        "        print(f\"[Trial {trial.number:2d}] steps={steps}, alpha={alpha}, ASR={asr:.4f}, clean_acc={clean_acc:.4f}, adv_acc={adv_acc:.4f}\")\n",
        "        return asr\n",
        "\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    try:\n",
        "        study.optimize(objective, n_trials=30, callbacks=[plateau_callback])\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOptimization stopped manually!\")\n",
        "        print(\"Saving current best parameters...\")\n",
        "    finally:\n",
        "        # This block will execute whether optimization completes normally or is interrupted\n",
        "        best_params = study.best_params\n",
        "        best_value = study.best_value\n",
        "        print(f\"Best params: {best_params}\")\n",
        "        print(f\"Best ASR   : {best_value}\")\n",
        "        print(\"ASR progress plot saved as 'asr_progress.png'\")\n",
        "\n",
        "        with open(\"best_params.pkl\", \"wb\") as f:\n",
        "            pickle.dump(best_params, f)\n",
        "\n",
        "else:\n",
        "    base_cnt = adv_cnt = 0\n",
        "    for t, query in enumerate(queries, start=1):\n",
        "        b, a = run_alg1_with_query(train_ds, query, t)\n",
        "        base_cnt += b\n",
        "        adv_cnt  += a\n",
        "\n",
        "    clean_acc = base_cnt / len(queries)\n",
        "    adv_acc   = adv_cnt  / len(queries)\n",
        "    asr       = 1.0 - (adv_acc / clean_acc) if clean_acc > 0 else 0.0\n",
        "    print(f\"Normal → clean_acc={clean_acc:.3f}, adv_acc={adv_acc:.3f}, ASR={asr:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b06b01e",
      "metadata": {
        "id": "9b06b01e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "import pickle\n",
        "import optuna\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "TUNE = False\n",
        "\n",
        "\n",
        "USE_SAVED_PARAMS = True\n",
        "\n",
        "\n",
        "loss_type  = \"Sentiment\"\n",
        "num_shots  = 4\n",
        "n_edit     = 3\n",
        "\n",
        "steps      = 40\n",
        "alpha      = 3\n",
        "\n",
        "eps        = 100.0\n",
        "k_nn       = 10\n",
        "\n",
        "trials     = 20\n",
        "seed       = 72\n",
        "device     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "verbose    = True\n",
        "\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "param_grid = {\n",
        "    'steps': [40, 80],\n",
        "    'alpha': [3],\n",
        "}\n",
        "\n",
        "\n",
        "def load_cached_model(model_id=\"facebook/opt-30b\"):\n",
        "    global model, tok, E, V, d, pos_id, neg_id\n",
        "    cache = (\"model\",\"tok\",\"E\",\"V\",\"d\",\"pos_id\",\"neg_id\")\n",
        "    if getattr(globals().get(\"model\",None),\"name_or_path\",None)==model_id \\\n",
        "       and all(v in globals() for v in cache):\n",
        "        return model, tok, E, V, d, pos_id, neg_id\n",
        "\n",
        "    if \"model\" in globals():\n",
        "        del model\n",
        "        for v in cache[1:]:\n",
        "            globals().pop(v,None)\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "    tok = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)\n",
        "    tok.pad_token = tok.eos_token\n",
        "   ### quant\n",
        "    quant_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_use_double_quant=True\n",
        "    )\n",
        "   ### quant\n",
        "\n",
        "\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        quantization_config=quant_config,\n",
        "        device_map=\"auto\"\n",
        "    ).eval()\n",
        "\n",
        "    model.name_or_path = model_id\n",
        "\n",
        "    E      = model.get_input_embeddings().weight\n",
        "    V, d   = E.shape\n",
        "    pos_id = tok(\"positive\", add_special_tokens=False)[\"input_ids\"][0]\n",
        "    neg_id = tok(\"negative\", add_special_tokens=False)[\"input_ids\"][0]\n",
        "    return model, tok, E, V, d, pos_id, neg_id\n",
        "\n",
        "model, tok, E, V, d, pos_id, neg_id = load_cached_model()\n",
        "\n",
        "label_word = {1:\"positive\",0:\"negative\"}\n",
        "topic_word = {0:\"world\",1:\"sports\",2:\"business\",3:\"technology\"}\n",
        "\n",
        "\n",
        "train_ds = load_dataset(\"glue\",\"sst2\",split=\"train\")\n",
        "val_ds   = load_dataset(\"glue\",\"sst2\",split=\"validation\")\n",
        "\n",
        "\n",
        "traverse_full_val = False\n",
        "\n",
        "\n",
        "if not TUNE and USE_SAVED_PARAMS:\n",
        "    if os.path.exists(\"best_params.pkl\"):\n",
        "        best = pickle.load(open(\"best_params.pkl\", \"rb\"))\n",
        "        steps = best[\"steps\"]\n",
        "        alpha = best[\"alpha\"]\n",
        "    else:\n",
        "        print(\"Warning: best_params.pkl not found, using defaults.\")\n",
        "#     traverse_full_val = True\n",
        "\n",
        "if traverse_full_val:\n",
        "    queries = list(val_ds)\n",
        "    trials  = len(queries)\n",
        "else:\n",
        "    queries = random.sample(list(val_ds), trials)\n",
        "\n",
        "\n",
        "def build_prompt(demo_df, q_sent, q_lbl):\n",
        "    if loss_type==\"Topic\":\n",
        "        instr=\"Classify the topic of the last review. Here are several examples.\"\n",
        "        tag=\"\\nTopic:\"; labmap=topic_word\n",
        "        tgt = tok(labmap[q_lbl],add_special_tokens=False)[\"input_ids\"][0]\n",
        "    else:\n",
        "        instr=(\n",
        "          \"Analyze the sentiment of the last review and respond with \"\n",
        "          \"either positive or negative. Here are several examples.\"\n",
        "        )\n",
        "        tag=\"\\nSentiment:\"; labmap=label_word\n",
        "        tgt = pos_id if q_lbl==1 else neg_id\n",
        "\n",
        "    demos_str=\"\"; demo_sents=[]\n",
        "    for sent,lab in zip(demo_df[\"sentence\"][:num_shots],\n",
        "                        demo_df[\"label\"][:num_shots]):\n",
        "        s=sent.strip(); demo_sents.append(s)\n",
        "        demos_str+=f\"\\nReview: {s}{tag}{labmap[lab]}\"\n",
        "    q_stub=f\"\\nReview: {q_sent.strip()}{tag[:-1]}:\"\n",
        "    return f\"{instr}\\n{demos_str}{q_stub}\", demo_sents, tgt\n",
        "\n",
        "def classify_token(ids):\n",
        "    lg = model(ids.unsqueeze(0)).logits[0,-1]\n",
        "    if lg[pos_id]>lg[neg_id]:\n",
        "        p=pos_id; prob=torch.softmax(lg[[neg_id,pos_id]],0)[1].item()\n",
        "    else:\n",
        "        p=neg_id; prob=torch.softmax(lg[[neg_id,pos_id]],0)[0].item()\n",
        "    return p, prob\n",
        "\n",
        "def run_alg1_with_query(train_ds, query, trial_idx):\n",
        "    demo_df = pd.DataFrame(random.sample(list(train_ds), num_shots))\n",
        "    prompt, demo_sents, tgt_id = build_prompt(\n",
        "        demo_df, query[\"sentence\"], query[\"label\"]\n",
        "    )\n",
        "    enc = tok(prompt,\n",
        "              return_tensors=\"pt\",\n",
        "              return_offsets_mapping=True,\n",
        "              add_special_tokens=False).to(device)\n",
        "    ids  = enc.input_ids[0]\n",
        "    mask = enc.attention_mask[0]\n",
        "    offs = enc.offset_mapping[0].tolist()\n",
        "\n",
        "    spans=[]\n",
        "    for s in demo_sents:\n",
        "        cs,ce=prompt.index(s),prompt.index(s)+len(s)\n",
        "        tok_s=next(i for i,(a,b) in enumerate(offs) if a<=cs<b)\n",
        "        tok_e=next(i for i,(a,b) in enumerate(offs) if a<ce<=b)+1\n",
        "        spans.append([tok_s,tok_e,[]])\n",
        "\n",
        "\n",
        "    if loss_type==\"Topic\":\n",
        "        tag=\"\\nTopic:\"; labmap=topic_word\n",
        "    else:\n",
        "        tag=\"\\nSentiment:\"; labmap=label_word\n",
        "    label_spans = []\n",
        "    for sent, lab in zip(demo_sents, demo_df[\"label\"][:num_shots]):\n",
        "        sent_idx = prompt.index(sent)\n",
        "        char_start = prompt.find(tag+labmap[lab], sent_idx+len(sent))\n",
        "        char_end = char_start + len(tag+labmap[lab])\n",
        "        tokens = [i for i,(a,b) in enumerate(offs) if b>char_start and a<char_end]\n",
        "        label_spans.append(tokens)\n",
        "\n",
        "    pred_b,prob_b=classify_token(ids)\n",
        "    base_ok=(pred_b==tgt_id)\n",
        "\n",
        "\n",
        "    pre_eps=eps/num_shots\n",
        "    delta_pre=torch.zeros_like(E[ids],requires_grad=True)\n",
        "    for _ in range(steps):\n",
        "        out=model(inputs_embeds=(E[ids]+delta_pre).unsqueeze(0),\n",
        "                  attention_mask=mask.unsqueeze(0)).logits[0,-1]\n",
        "        loss=F.cross_entropy(out.unsqueeze(0),\n",
        "                             torch.tensor([tgt_id],device=device))\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for s,e,posL in spans:\n",
        "                delta_pre[s:e]+=alpha*delta_pre.grad[s:e]\n",
        "                if delta_pre[s:e].norm()>pre_eps:\n",
        "                    delta_pre[s:e]*=pre_eps/delta_pre[s:e].norm()\n",
        "            delta_pre.grad.zero_()\n",
        "\n",
        "    for s,e,posL in spans:\n",
        "        norms=delta_pre[s:e].norm(dim=1)\n",
        "        topk =norms.topk(min(n_edit,e-s)).indices+s\n",
        "        posL.extend(topk.tolist())\n",
        "\n",
        "\n",
        "    delta=torch.zeros_like(E[ids],requires_grad=True)\n",
        "    trace=[]\n",
        "    for _ in range(steps):\n",
        "        out=model(inputs_embeds=(E[ids]+delta).unsqueeze(0),\n",
        "                  attention_mask=mask.unsqueeze(0)).logits[0,-1]\n",
        "        loss=F.cross_entropy(out.unsqueeze(0),\n",
        "                             torch.tensor([tgt_id],device=device))\n",
        "        trace.append(loss.item()); loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for _,_,posL in spans:\n",
        "                for p in posL:\n",
        "                    delta[p]+=alpha*delta.grad[p]\n",
        "            if delta.norm()>eps: delta.mul_(eps/delta.norm())\n",
        "            delta.grad.zero_()\n",
        "\n",
        "    ids_adv=ids.clone()\n",
        "    save_dict = {\n",
        "        \"demo_df\":    demo_df.to_dict(),\n",
        "        \"query\":      {\"sentence\": query[\"sentence\"], \"label\": query[\"label\"]},\n",
        "        \"spans\":      spans,\n",
        "        \"delta\":      delta.detach().cpu().numpy(),\n",
        "        \"ice\":        {},\n",
        "        \"label_spans\": label_spans\n",
        "    }\n",
        "    for idx,(s,e,posL) in enumerate(spans,1):\n",
        "        toks=[]\n",
        "        for p in posL:\n",
        "            orig=ids[p].item()\n",
        "            best_id = None\n",
        "            tgtv=E[orig]+delta[p]\n",
        "            mask_ball=(E-E[orig]).norm(dim=1)<=eps\n",
        "            cands=torch.where(mask_ball)[0]\n",
        "            if cands.numel()>0:\n",
        "                dists=(E[cands]-tgtv).norm(dim=1)\n",
        "                best_id = int(cands[dists.topk(min(k_nn,cands.numel()),\n",
        "                                              largest=False).indices[0]])\n",
        "                ids_adv[p]=best_id\n",
        "            toks.append({\n",
        "              'pos':p,\n",
        "              'orig_token':tok.convert_ids_to_tokens([orig])[0],\n",
        "              'adv_token' :tok.convert_ids_to_tokens([best_id])[0] if best_id is not None else None,\n",
        "              'orig_embedding':E[orig].detach().cpu().numpy(),\n",
        "              'adv_embedding':E[best_id].detach().cpu().numpy() if best_id is not None else None,\n",
        "              'delta':delta[p].detach().cpu().numpy()\n",
        "            })\n",
        "        save_dict[\"ice\"][f\"ICE_{idx}\"] = {\n",
        "          'pre_text':   tok.decode(ids[s:e],skip_special_tokens=True),\n",
        "          'post_text':  tok.decode(ids_adv[s:e],skip_special_tokens=True),\n",
        "          'token_info': toks\n",
        "        }\n",
        "\n",
        "\n",
        "    pred_a,prob_a = classify_token(ids_adv)\n",
        "    adv_ok        = (pred_a==tgt_id)\n",
        "    clean_acc     = float(base_ok)\n",
        "    adv_acc       = float(adv_ok)\n",
        "    drop          = clean_acc - adv_acc\n",
        "    asr           = 1.0 - (adv_acc / clean_acc) if clean_acc>0 else 0.0\n",
        "\n",
        "    print(f\"\\n=== Metrics Trial {trial_idx} ===\")\n",
        "    print(f\"  clean_acc: {clean_acc:.3f}\")\n",
        "    print(f\"  adv_acc  : {adv_acc:.3f}\")\n",
        "    print(f\"  drop     : {drop:.3f}\")\n",
        "    print(f\"  ASR      : {asr:.3f}\")\n",
        "\n",
        "    save_dict[\"metrics\"] = {\n",
        "        \"clean_acc\": clean_acc,\n",
        "        \"adv_acc\":   adv_acc,\n",
        "        \"drop\":      drop,\n",
        "        \"ASR\":       asr\n",
        "    }\n",
        "\n",
        "    os.makedirs(\"perturb_info\",exist_ok=True)\n",
        "    with open(f\"perturb_info/ice_deltas_trial_{trial_idx}.pkl\",\"wb\") as f:\n",
        "        pickle.dump(save_dict,f)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n=== Alg1 Trial {trial_idx} ===\")\n",
        "        print(\"loss trace:\",[f\"{x:.3f}\" for x in trace])\n",
        "        print(f\"Baseline    : {tok.convert_ids_to_tokens([pred_b])[0]} (p={prob_b:.2f})\",\"✓\" if base_ok else \"✗\")\n",
        "        print(f\"AfterAttack : {tok.convert_ids_to_tokens([pred_a])[0]} (p={prob_a:.2f})\",\"✓\" if adv_ok else \"✗\")\n",
        "        print(\"\\n--- ICE Replacement Details ---\")\n",
        "        for idx,(s,e,posL) in enumerate(spans,1):\n",
        "            before=tok.decode(ids[s:e],skip_special_tokens=True)\n",
        "            after =tok.decode(ids_adv[s:e],skip_special_tokens=True)\n",
        "            repl  =[(tok.convert_ids_to_tokens([ids[p]])[0],\n",
        "                     tok.convert_ids_to_tokens([ids_adv[p]])[0]) for p in posL]\n",
        "            print(f\"\\nICE {idx}:\")\n",
        "            print(\"  Before:\",before)\n",
        "            print(\"  After: \",after)\n",
        "            print(\"  Replaced tokens:\",repl)\n",
        "\n",
        "    return base_ok, adv_ok\n",
        "\n",
        "\n",
        "if TUNE:\n",
        "\n",
        "    _plateau = {\"best\": 0.0, \"count\": 0}\n",
        "    _asr_history = []\n",
        "\n",
        "    def plateau_callback(study, trial):\n",
        "        global _asr_history, _plateau\n",
        "        val = trial.value\n",
        "        _asr_history.append(val)\n",
        "\n",
        "        if val > _plateau[\"best\"] + 1e-3:\n",
        "            _plateau[\"best\"] = val\n",
        "            _plateau[\"count\"] = 0\n",
        "        else:\n",
        "            _plateau[\"count\"] += 1\n",
        "        if _plateau[\"count\"] >= 5:\n",
        "            study.stop()\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(_asr_history, marker='o')\n",
        "        plt.title('ASR up')\n",
        "        plt.xlabel('trial number')\n",
        "        plt.ylabel('(ASR)')\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('asr_progress.png')\n",
        "\n",
        "\n",
        "        try:\n",
        "            plt.show(block=False)\n",
        "            plt.pause(0.1)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "    def objective(trial):\n",
        "        global steps, alpha\n",
        "        steps = trial.suggest_categorical(\"steps\", param_grid['steps'])\n",
        "        alpha = trial.suggest_categorical(\"alpha\", param_grid['alpha'])\n",
        "\n",
        "        base_cnt = adv_cnt = 0\n",
        "        for t, query in enumerate(queries, start=1):\n",
        "            b, a = run_alg1_with_query(train_ds, query, t)\n",
        "            base_cnt += b\n",
        "            adv_cnt  += a\n",
        "\n",
        "        clean_acc = base_cnt / len(queries)\n",
        "        adv_acc   = adv_cnt  / len(queries)\n",
        "        asr       = 1.0 - (adv_acc / clean_acc) if clean_acc > 0 else 0.0\n",
        "\n",
        "        print(f\"[Trial {trial.number:2d}] steps={steps}, alpha={alpha}, ASR={asr:.4f}, clean_acc={clean_acc:.4f}, adv_acc={adv_acc:.4f}\")\n",
        "        return asr\n",
        "\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    try:\n",
        "        study.optimize(objective, n_trials=30, callbacks=[plateau_callback])\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOptimization stopped manually!\")\n",
        "        print(\"Saving current best parameters...\")\n",
        "    finally:\n",
        "\n",
        "        best_params = study.best_params\n",
        "        best_value = study.best_value\n",
        "        print(f\"Best params: {best_params}\")\n",
        "        print(f\"Best ASR   : {best_value}\")\n",
        "        print(\"ASR progress plot saved as 'asr_progress.png'\")\n",
        "\n",
        "        with open(\"best_params.pkl\", \"wb\") as f:\n",
        "            pickle.dump(best_params, f)\n",
        "\n",
        "else:\n",
        "    base_cnt = adv_cnt = 0\n",
        "    for t, query in enumerate(queries, start=1):\n",
        "        b, a = run_alg1_with_query(train_ds, query, t)\n",
        "        base_cnt += b\n",
        "        adv_cnt  += a\n",
        "\n",
        "    clean_acc = base_cnt / len(queries)\n",
        "    adv_acc   = adv_cnt  / len(queries)\n",
        "    asr       = 1.0 - (adv_acc / clean_acc) if clean_acc > 0 else 0.0\n",
        "    print(f\"Normal → clean_acc={clean_acc:.3f}, adv_acc={adv_acc:.3f}, ASR={asr:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2396b5ad",
      "metadata": {
        "id": "2396b5ad"
      },
      "outputs": [],
      "source": [
        "## profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79774507",
      "metadata": {
        "id": "79774507"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "\n",
        "input_dir = \"perturb_info\"\n",
        "\n",
        "\n",
        "first_path = os.path.join(input_dir, \"ice_deltas_trial_1.pkl\")\n",
        "with open(first_path, \"rb\") as f:\n",
        "    first = pickle.load(f)\n",
        "n = len(first[\"ice\"])  # ICE_1 … ICE_n\n",
        "\n",
        "\n",
        "all_delta_norms = []\n",
        "valid_trials    = []\n",
        "\n",
        "\n",
        "paths = sorted(glob.glob(os.path.join(input_dir, \"ice_deltas_trial_*.pkl\")))\n",
        "for path in paths:\n",
        "\n",
        "    fname = os.path.basename(path)\n",
        "    t = int(fname.split(\"_\")[-1].split(\".\")[0])\n",
        "    with open(path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    norms = []\n",
        "    for i in range(1, n + 1):\n",
        "        token_info = data[\"ice\"][f\"ICE_{i}\"][\"token_info\"]\n",
        "\n",
        "        deltas_i = torch.stack([torch.tensor(entry[\"delta\"]) for entry in token_info])\n",
        "        norms.append(deltas_i.norm(dim=1).sum().item())\n",
        "\n",
        "    norms = np.array(norms, dtype=float)\n",
        "    if np.isnan(norms).any():\n",
        "        print(f\"[Warning] trial {t} contain NaN, skip: {norms}\")\n",
        "        continue\n",
        "\n",
        "    all_delta_norms.append(norms)\n",
        "    valid_trials.append(t)\n",
        "\n",
        "if len(all_delta_norms) == 0:\n",
        "    raise RuntimeError(\"skip Budget Profile\")\n",
        "\n",
        "all_delta_norms = np.vstack(all_delta_norms)\n",
        "print(f\"use effective trials: {valid_trials}\")\n",
        "print(\"all trial ICEs of L2 norms:\\n\", all_delta_norms)\n",
        "\n",
        "\n",
        "mean_delta_norms = all_delta_norms.mean(axis=0)\n",
        "print(\"average ICE L2:\", mean_delta_norms)\n",
        "\n",
        "\n",
        "total = mean_delta_norms.sum()\n",
        "if total <= 0:\n",
        "    raise RuntimeError(\"can not normalize\")\n",
        "gamma_disc = mean_delta_norms / total\n",
        "print(\"Discretize Budget Profile γ:\", gamma_disc.tolist())\n",
        "\n",
        "def to_continuous_budget(gamma, N):\n",
        "    gamma  = np.array(gamma, dtype=float)\n",
        "    x_orig = np.arange(1, gamma.size + 1)\n",
        "    interp = interp1d(\n",
        "        x_orig, gamma,\n",
        "        kind=\"linear\",\n",
        "        bounds_error=False,\n",
        "        fill_value=\"extrapolate\"\n",
        "    )\n",
        "    x_new = np.linspace(1, gamma.size, N)\n",
        "    vals  = np.clip(interp(x_new), 0, None)\n",
        "    return vals / vals.sum()\n",
        "\n",
        "custom_gamma = to_continuous_budget(gamma_disc, n)\n",
        "print(f\"\\ncontinuous Budget Profile γ (length = {n}):\\n{custom_gamma.tolist()}\")\n",
        "print(\"Sum check:\", custom_gamma.sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae966f5a",
      "metadata": {
        "id": "ae966f5a"
      },
      "outputs": [],
      "source": [
        "##alg2-flat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac7829a",
      "metadata": {
        "id": "bac7829a",
        "outputId": "2f2ff1d9-8a1f-4e72-cc03-052625de6254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Alg1 best params: steps_local=80, alpha=3\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 1 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== Full debug_info for trial 1 ===\n",
            "{'trial': 1, 'full_pre': \"Analyze the sentiment of the last review and respond with either positive or negative. Here are several examples.\\nReview: the hallmarks\\nSentiment:positive\\nReview: about something , one that attempts and often achieves a level of connection and concern\\nSentiment:positive\\nReview: a movie to forget\\nSentiment:negative\\nReview: better thriller\\nSentiment:positive\\nReview: among the year 's most intriguing explorations of alientation .\\nSentiment:\", 'full_post': \"Analyze the sentiment of the last review and respond with either positive or negative. Here are several examples.\\nReview: the�ageddonSentiment:positive\\nReview: about something , that tried will often reduces it lvl ofnatureconservancy is Sentiment:positive\\nReview: aHonestly/channelAvailability isSentiment:negative\\nReview: better sketches consumerSentiment:positive\\nReview: among the year 's most intriguing explorations of alientation .\\nSentiment:\", 'ice': [{'ice_index': 1, 'pos': [25, 26, 27], 'pre_text': ' hallmarks\\n', 'post_text': '�ageddon', 'full_sent_pre': ' hallmarks\\n', 'full_sent_post': '�ageddon', 'clean_acc': 1.0, 'adv_acc': 1.0, 'drop': 0.0, 'ASR': 0.0}, {'ice_index': 2, 'pos': [50, 49, 47, 48, 40, 38, 45, 43, 41, 44], 'pre_text': '', 'post_text': '', 'full_sent_pre': ' something , one that attempts and often achieves a level of connection and concern\\n', 'full_sent_post': ' something , that tried will often reduces it lvl ofnatureconservancy is ', 'clean_acc': 1.0, 'adv_acc': 1.0, 'drop': 0.0, 'ASR': 0.0}, {'ice_index': 3, 'pos': [61, 62, 59, 60], 'pre_text': '', 'post_text': '', 'full_sent_pre': ' movie to forget\\n', 'full_sent_post': 'Honestly/channelAvailability is', 'clean_acc': 1.0, 'adv_acc': 1.0, 'drop': 0.0, 'ASR': 0.0}, {'ice_index': 4, 'pos': [72, 71], 'pre_text': '', 'post_text': '', 'full_sent_pre': ' thriller\\n', 'full_sent_post': ' sketches consumer', 'clean_acc': 1.0, 'adv_acc': 1.0, 'drop': 0.0, 'ASR': 0.0}]}\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 2 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 3 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 4 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "\n",
            "=== Alg2 Trial 5 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 1.000\n",
            " ASR      : 1.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 6 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "\n",
            "=== Alg2 Trial 7 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 1.000\n",
            " ASR      : 1.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 8 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 9 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "\n",
            "=== Alg2 Trial 10 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 1.000\n",
            " ASR      : 1.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 11 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 12 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 13 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 14 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 15 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "\n",
            "=== Alg2 Trial 16 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 1.000\n",
            " ASR      : 1.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 17 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 18 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "\n",
            "=== Alg2 Trial 19 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 1.000\n",
            " ASR      : 1.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 20 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "\n",
            "=== Overall Alg2 (last ICE) ===\n",
            "Avg clean_acc: 0.600\n",
            "Avg adv_acc  : 0.450\n",
            "Avg drop     : 0.150\n",
            "Avg ASR      : 0.250\n",
            "\n",
            "=== Per-ICE Average Metrics Across All Trials ===\n",
            "ICE 1: clean_acc=0.600, adv_acc=0.550, drop=0.250, ASR=0.250\n",
            "ICE 2: clean_acc=0.700, adv_acc=0.350, drop=0.400, ASR=0.400\n",
            "ICE 3: clean_acc=0.600, adv_acc=0.350, drop=0.250, ASR=0.250\n",
            "ICE 4: clean_acc=0.600, adv_acc=0.450, drop=0.250, ASR=0.250\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import glob\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "steps_local = 2\n",
        "\n",
        "# 1) If Alg1 tuned and wrote best_params.pkl, reuse those steps & alpha\n",
        "try:\n",
        "    best = pickle.load(open(\"best_params.pkl\", \"rb\"))\n",
        "    steps_local = best[\"steps\"]\n",
        "    alpha       = best[\"alpha\"]\n",
        "    print(f\"Using Alg1 best params: steps_local={steps_local}, alpha={alpha}\")\n",
        "except FileNotFoundError:\n",
        "    pass\n",
        "\n",
        "def word_proj(ids_orig, pos_sel, delta_vec, eps_bound, tgt_q, mask):\n",
        "    ids_new = ids_orig.clone()\n",
        "    for p in pos_sel:\n",
        "        orig = ids_orig[p].item()\n",
        "        tgtv = E[orig] + delta_vec[p]\n",
        "        ball = (E - E[orig]).norm(dim=1) <= eps_bound\n",
        "        cands = torch.arange(V, device=device)[ball]\n",
        "        if cands.numel() == 0: continue\n",
        "        dists = (E[cands] - tgtv).norm(dim=1)\n",
        "        topk  = cands[dists.topk(min(k_nn,cands.numel()), largest=False).indices]\n",
        "        best, best_loss = orig, -1e9\n",
        "        for cid in topk:\n",
        "            tmp = ids_orig.clone(); tmp[p] = cid\n",
        "            loss = F.cross_entropy(\n",
        "                model(tmp.unsqueeze(0), attention_mask=mask.unsqueeze(0)).logits[0,-1].unsqueeze(0),\n",
        "                torch.tensor([tgt_q], device=device)\n",
        "            )\n",
        "            if loss.item() > best_loss:\n",
        "                best_loss = loss.item(); best = cid.item()\n",
        "        ids_new[p] = best\n",
        "    return ids_new\n",
        "\n",
        "def run_alg2_on(demo_df, query, spans, delta_global, label_spans, trial):\n",
        "    # 1) Construct the complete prompt, including all ICEs + query\n",
        "    head = (\"Analyze the sentiment of the last review and respond with \"\n",
        "            \"either positive or negative. Here are several examples.\")\n",
        "    tag  = \"\\nSentiment:\"\n",
        "    demos = list(zip(demo_df[\"sentence\"], demo_df[\"label\"]))\n",
        "    prompt = head + \"\".join(\n",
        "        f\"\\nReview: {s.strip()}{tag}{label_word[l]}\" for s,l in demos\n",
        "    ) + f\"\\nReview: {query['sentence'].strip()}\\nSentiment:\"\n",
        "    enc = tok(prompt, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "    ids, full_mask = enc.input_ids[0], enc.attention_mask[0]\n",
        "\n",
        "    # 2) Pre-calculate clean prediction on the full prompt\n",
        "    pred_b, prob_b = classify_token(ids)\n",
        "    base_ok = (pred_b == (pos_id if query[\"label\"]==1 else neg_id))\n",
        "\n",
        "    # 3) Sequential PGD\n",
        "    gamma = [1.0]*num_shots\n",
        "    gamma = [g/sum(gamma) for g in gamma]\n",
        "    eps_i = [g*eps for g in gamma]\n",
        "    cum_delta = torch.zeros_like(E[ids], device=device)\n",
        "\n",
        "    # Prepare to store per-ICE metrics\n",
        "    metrics_per_ice = []\n",
        "\n",
        "    for i,(_,_,posL) in enumerate(spans):\n",
        "        # mask subsequent ICE_{i+1..n}\n",
        "        mask_i = full_mask.clone()\n",
        "        for j in range(i+1,len(spans)):\n",
        "            s_j,e_j,_ = spans[j]\n",
        "            mask_i[s_j:e_j] = 0\n",
        "            for lp in label_spans[j]:\n",
        "                mask_i[lp] = 0\n",
        "\n",
        "        # 3.1) Local PGD for ICE_i\n",
        "        delta_loc = cum_delta.clone().detach().requires_grad_(True)\n",
        "        for _ in range(steps_local):\n",
        "            emb = E[ids] + delta_loc\n",
        "            logits = model(inputs_embeds=emb.unsqueeze(0),\n",
        "                           attention_mask=mask_i.unsqueeze(0)).logits[0,-1]\n",
        "            tgt_q = pos_id if query[\"label\"]==1 else neg_id\n",
        "            loss = F.cross_entropy(logits.unsqueeze(0),\n",
        "                                   torch.tensor([tgt_q],device=device))\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in posL:\n",
        "                    delta_loc[p] += alpha * delta_loc.grad[p]\n",
        "                span_vec = delta_loc[posL]\n",
        "                norm = span_vec.norm()\n",
        "                if norm > eps_i[i]:\n",
        "                    delta_loc[posL] *= eps_i[i]/norm\n",
        "                delta_loc.grad.zero_()\n",
        "        with torch.no_grad():\n",
        "            for p in posL:\n",
        "                cum_delta[p] = delta_loc[p]\n",
        "\n",
        "\n",
        "        tgt_q = pos_id if query[\"label\"]==1 else neg_id\n",
        "        prefix_prompt = head + \"\".join(\n",
        "            f\"\\nReview: {demos[k][0].strip()}{tag}{label_word[demos[k][1]]}\"\n",
        "            for k in range(i+1)\n",
        "        ) + f\"\\nReview: {query['sentence'].strip()}\\nSentiment:\"\n",
        "        enc_clean = tok(prefix_prompt, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "        ids_clean = enc_clean.input_ids[0]\n",
        "        pred_c, _ = classify_token(ids_clean)\n",
        "        clean_acc_i = 1.0 if pred_c==tgt_q else 0.0\n",
        "\n",
        "        # cumulative word_proj for ICE_1…ICE_i\n",
        "        ids_tmp = ids.clone()\n",
        "        for j in range(i+1):\n",
        "            _,_,posL_j = spans[j]\n",
        "            ids_tmp = word_proj(\n",
        "                ids_tmp,\n",
        "                posL_j,\n",
        "                cum_delta,\n",
        "                eps_i[j],\n",
        "                tgt_q,\n",
        "                full_mask\n",
        "            )\n",
        "        pred_i, _ = classify_token(ids_tmp)\n",
        "        adv_ok_i = (pred_i == tgt_q)\n",
        "\n",
        "        # compute adv_acc_i, drop_i, ASR_i with clamping and correct definition\n",
        "        adv_acc_i = 1.0 if adv_ok_i else 0.0\n",
        "        drop_i    = max(clean_acc_i - adv_acc_i, 0.0)\n",
        "        ASR_i     = 1.0 if (clean_acc_i==1.0 and adv_acc_i==0.0) else 0.0\n",
        "\n",
        "        print(f\"=== ICE {i+1} Metrics === clean_acc: {clean_acc_i:.3f}, adv_acc: {adv_acc_i:.3f}, drop: {drop_i:.3f}, ASR: {ASR_i:.3f}\")\n",
        "\n",
        "        metrics_per_ice.append({\n",
        "            \"clean_acc\": clean_acc_i,\n",
        "            \"adv_acc\":   adv_acc_i,\n",
        "            \"drop\":      drop_i,\n",
        "            \"ASR\":       ASR_i\n",
        "        })\n",
        "\n",
        "    # 4) Final full-word_proj across all spans\n",
        "    ids_adv = ids.clone()\n",
        "    tgt_q   = pos_id if query[\"label\"]==1 else neg_id\n",
        "    for i,(_,_,posL) in enumerate(spans):\n",
        "        ids_adv = word_proj(ids_adv, posL, cum_delta, eps_i[i], tgt_q, full_mask)\n",
        "\n",
        "    # 5) Last-ICE metrics (same definitions)\n",
        "    pred_a, _ = classify_token(ids_adv)\n",
        "    adv_ok    = (pred_a == tgt_q)\n",
        "    clean_acc = 1.0 if base_ok else 0.0\n",
        "    adv_acc   = 1.0 if adv_ok   else 0.0\n",
        "    drop      = max(clean_acc - adv_acc, 0.0)\n",
        "    ASR       = 1.0 if (clean_acc==1.0 and adv_acc==0.0) else 0.0\n",
        "\n",
        "    print(f\"\\n=== Alg2 Trial {trial} Metrics (last ICE) ===\")\n",
        "    print(f\" clean_acc: {clean_acc:.3f}\")\n",
        "    print(f\" adv_acc  : {adv_acc:.3f}\")\n",
        "    print(f\" drop     : {drop:.3f}\")\n",
        "    print(f\" ASR      : {ASR:.3f}\")\n",
        "\n",
        "    # 6) save per-ICE metrics + texts into debug_info pkl\n",
        "    #    AND record the full prompt before and after all perturbations\n",
        "    full_pre  = tok.decode(ids,    skip_special_tokens=True)\n",
        "    full_post = tok.decode(ids_adv, skip_special_tokens=True)\n",
        "\n",
        "    debug_info = {\n",
        "        'trial':      trial,\n",
        "        'full_pre':   full_pre,\n",
        "        'full_post':  full_post,\n",
        "        'ice':        []\n",
        "    }\n",
        "\n",
        "    for i, (s_j, e_j, posL) in enumerate(spans):\n",
        "        sent_pre  = tok.decode(ids[s_j:e_j],     skip_special_tokens=True)\n",
        "        sent_post = tok.decode(ids_adv[s_j:e_j], skip_special_tokens=True)\n",
        "\n",
        "        entry = {\n",
        "            \"ice_index\":      i + 1,\n",
        "            \"pos\":            posL,\n",
        "            \"pre_text\":       tok.decode(ids[posL[0]:posL[-1]+1],     skip_special_tokens=True),\n",
        "            \"post_text\":      tok.decode(ids_adv[posL[0]:posL[-1]+1], skip_special_tokens=True),\n",
        "            \"full_sent_pre\":  sent_pre,\n",
        "            \"full_sent_post\": sent_post,\n",
        "            **metrics_per_ice[i]\n",
        "        }\n",
        "        debug_info[\"ice\"].append(entry)\n",
        "\n",
        "    os.makedirs(\"perturb_info_flat\", exist_ok=True)\n",
        "    with open(f\"perturb_info_flat/alg2_debug_trial_{trial}.pkl\",\"wb\") as f:\n",
        "        pickle.dump(debug_info,f)\n",
        "\n",
        "    # 1) NEW: on first trial, print entire saved debug_info\n",
        "    if trial == 1:\n",
        "        print(\"=== Full debug_info for trial 1 ===\")\n",
        "        print(debug_info)\n",
        "\n",
        "    return [clean_acc], [adv_acc]\n",
        "\n",
        "# # ─────────────────────────────────────────────────────────────────────────────\n",
        "# # Batch load, run Alg2, and compute averages\n",
        "# # ─────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# Batch load from Alg1 saved PKLs, run Alg2 and collect metrics\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "base2_sum = 0.0\n",
        "adv2_sum  = 0.0\n",
        "all_metrics = []\n",
        "\n",
        "orig_paths = sorted(glob.glob(\"perturb_info/ice_deltas_trial_*.pkl\"))\n",
        "for t, orig_path in enumerate(orig_paths, start=1):\n",
        "\n",
        "    data = pickle.load(open(orig_path, \"rb\"))\n",
        "    demo_df      = pd.DataFrame.from_dict(data[\"demo_df\"])\n",
        "    query        = data[\"query\"]\n",
        "    spans        = data[\"spans\"]\n",
        "    delta_global = torch.tensor(data[\"delta\"], device=device)\n",
        "    label_spans  = data[\"label_spans\"]\n",
        "\n",
        "\n",
        "    b_vec, a_vec = run_alg2_on(demo_df, query, spans, delta_global, label_spans, t)\n",
        "    base2_sum += b_vec[0]\n",
        "    adv2_sum  += a_vec[0]\n",
        "\n",
        "\n",
        "    flat_path = f\"perturb_info_flat/alg2_debug_trial_{t}.pkl\"\n",
        "    flat_data = pickle.load(open(flat_path, \"rb\"))\n",
        "    all_metrics.append(flat_data[\"ice\"])\n",
        "\n",
        "num_trials = len(all_metrics)\n",
        "\n",
        "# overall (last ICE) averages\n",
        "print(\"\\n=== Overall Alg2 (last ICE) ===\")\n",
        "print(f\"Avg clean_acc: {base2_sum/num_trials:.3f}\")\n",
        "print(f\"Avg adv_acc  : {adv2_sum/num_trials:.3f}\")\n",
        "print(f\"Avg drop     : {(base2_sum-adv2_sum)/num_trials:.3f}\")\n",
        "print(f\"Avg ASR      : {1-(adv2_sum/base2_sum) if base2_sum>0 else 0.0:.3f}\")\n",
        "\n",
        "# per-ICE averages\n",
        "print(\"\\n=== Per-ICE Average Metrics Across All Trials ===\")\n",
        "num_ice = len(all_metrics[0])\n",
        "sums = [ {'clean_acc':0,'adv_acc':0,'drop':0,'ASR':0} for _ in range(num_ice) ]\n",
        "for trial_metrics in all_metrics:\n",
        "    for i, m in enumerate(trial_metrics):\n",
        "        sums[i]['clean_acc'] += m['clean_acc']\n",
        "        sums[i]['adv_acc']   += m['adv_acc']\n",
        "        sums[i]['drop']      += m['drop']\n",
        "        sums[i]['ASR']       += m['ASR']\n",
        "for i, s in enumerate(sums, start=1):\n",
        "    print(f\"ICE {i}: clean_acc={s['clean_acc']/num_trials:.3f}, \"\n",
        "          f\"adv_acc={s['adv_acc']/num_trials:.3f}, \"\n",
        "          f\"drop={s['drop']/num_trials:.3f}, \"\n",
        "          f\"ASR={s['ASR']/num_trials:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a58d142",
      "metadata": {
        "id": "8a58d142"
      },
      "outputs": [],
      "source": [
        "#alg2-budgeted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b824ce",
      "metadata": {
        "id": "b6b824ce",
        "outputId": "972771e0-4d1f-4aaa-8132-71dad687b434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Alg1 best params: steps_local=80, alpha=3\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 1 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== Full debug_info for trial 1 ===\n",
            "{'trial': 1, 'full_pre': \"Analyze the sentiment of the last review and respond with either positive or negative. Here are several examples.\\nReview: the hallmarks\\nSentiment:positive\\nReview: about something , one that attempts and often achieves a level of connection and concern\\nSentiment:positive\\nReview: a movie to forget\\nSentiment:negative\\nReview: better thriller\\nSentiment:positive\\nReview: among the year 's most intriguing explorations of alientation .\\nSentiment:\", 'full_post': \"Analyze the sentiment of the last review and respond with either positive or negative. Here are several examples.\\nReview: the monster flying\\nSentiment:positive\\nReview: about something , not that try I often complainant thatCRIP of584\\n fear inSentiment:positive\\nReview: a time beatenWOR isSentiment:negative\\nReview: better sold-Sentiment:positive\\nReview: among the year 's most intriguing explorations of alientation .\\nSentiment:\", 'ice': [{'ice_index': 1, 'pos': [25, 26, 27], 'pre_text': ' hallmarks\\n', 'post_text': ' monster flying\\n', 'full_sent_pre': ' hallmarks\\n', 'full_sent_post': ' monster flying\\n', 'clean_acc': 1.0, 'adv_acc': 1.0, 'drop': 0.0, 'ASR': 0.0}, {'ice_index': 2, 'pos': [50, 49, 47, 48, 40, 38, 45, 43, 41, 44], 'pre_text': '', 'post_text': '', 'full_sent_pre': ' something , one that attempts and often achieves a level of connection and concern\\n', 'full_sent_post': ' something , not that try I often complainant thatCRIP of584\\n fear in', 'clean_acc': 1.0, 'adv_acc': 1.0, 'drop': 0.0, 'ASR': 0.0}, {'ice_index': 3, 'pos': [61, 62, 59, 60], 'pre_text': '', 'post_text': '', 'full_sent_pre': ' movie to forget\\n', 'full_sent_post': ' time beatenWOR is', 'clean_acc': 1.0, 'adv_acc': 1.0, 'drop': 0.0, 'ASR': 0.0}, {'ice_index': 4, 'pos': [72, 71], 'pre_text': '', 'post_text': '', 'full_sent_pre': ' thriller\\n', 'full_sent_post': ' sold-', 'clean_acc': 1.0, 'adv_acc': 1.0, 'drop': 0.0, 'ASR': 0.0}]}\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 2 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 3 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 4 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "\n",
            "=== Alg2 Trial 5 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 1.000\n",
            " ASR      : 1.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 6 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "\n",
            "=== Alg2 Trial 7 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 1.000\n",
            " ASR      : 1.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 8 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 9 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "\n",
            "=== Alg2 Trial 10 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 1.000\n",
            " ASR      : 1.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 11 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 12 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 13 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 14 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 15 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 2 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "\n",
            "=== Alg2 Trial 16 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 1.000\n",
            " ASR      : 1.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 17 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 0.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 18 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "=== ICE 1 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "=== ICE 4 Metrics === clean_acc: 1.000, adv_acc: 0.000, drop: 1.000, ASR: 1.000\n",
            "\n",
            "=== Alg2 Trial 19 Metrics (last ICE) ===\n",
            " clean_acc: 1.000\n",
            " adv_acc  : 0.000\n",
            " drop     : 1.000\n",
            " ASR      : 1.000\n",
            "=== ICE 1 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 2 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 3 Metrics === clean_acc: 1.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "=== ICE 4 Metrics === clean_acc: 0.000, adv_acc: 1.000, drop: 0.000, ASR: 0.000\n",
            "\n",
            "=== Alg2 Trial 20 Metrics (last ICE) ===\n",
            " clean_acc: 0.000\n",
            " adv_acc  : 1.000\n",
            " drop     : 0.000\n",
            " ASR      : 0.000\n",
            "\n",
            "=== Overall Alg2 (last ICE) ===\n",
            "Avg clean_acc: 0.600\n",
            "Avg adv_acc  : 0.400\n",
            "Avg drop     : 0.200\n",
            "Avg ASR      : 0.333\n",
            "\n",
            "=== Per-ICE Average Metrics Across All Trials ===\n",
            "ICE 1: clean_acc=0.600, adv_acc=0.500, drop=0.300, ASR=0.300\n",
            "ICE 2: clean_acc=0.700, adv_acc=0.400, drop=0.300, ASR=0.300\n",
            "ICE 3: clean_acc=0.600, adv_acc=0.450, drop=0.150, ASR=0.150\n",
            "ICE 4: clean_acc=0.600, adv_acc=0.400, drop=0.250, ASR=0.250\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import glob\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "steps_local = 2\n",
        "\n",
        "# 1) If Alg1 tuned and wrote best_params.pkl, reuse those steps & alpha\n",
        "try:\n",
        "    best = pickle.load(open(\"best_params.pkl\", \"rb\"))\n",
        "    steps_local = best[\"steps\"]\n",
        "    alpha       = best[\"alpha\"]\n",
        "    print(f\"Using Alg1 best params: steps_local={steps_local}, alpha={alpha}\")\n",
        "except FileNotFoundError:\n",
        "    pass\n",
        "\n",
        "def word_proj(ids_orig, pos_sel, delta_vec, eps_bound, tgt_q, mask):\n",
        "    ids_new = ids_orig.clone()\n",
        "    for p in pos_sel:\n",
        "        orig = ids_orig[p].item()\n",
        "        tgtv = E[orig] + delta_vec[p]\n",
        "        ball = (E - E[orig]).norm(dim=1) <= eps_bound\n",
        "        cands = torch.arange(V, device=device)[ball]\n",
        "        if cands.numel() == 0: continue\n",
        "        dists = (E[cands] - tgtv).norm(dim=1)\n",
        "        topk  = cands[dists.topk(min(k_nn,cands.numel()), largest=False).indices]\n",
        "        best, best_loss = orig, -1e9\n",
        "        for cid in topk:\n",
        "            tmp = ids_orig.clone(); tmp[p] = cid\n",
        "            loss = F.cross_entropy(\n",
        "                model(tmp.unsqueeze(0), attention_mask=mask.unsqueeze(0)).logits[0,-1].unsqueeze(0),\n",
        "                torch.tensor([tgt_q], device=device)\n",
        "            )\n",
        "            if loss.item() > best_loss:\n",
        "                best_loss = loss.item(); best = cid.item()\n",
        "        ids_new[p] = best\n",
        "    return ids_new\n",
        "\n",
        "def run_alg2_on(demo_df, query, spans, delta_global, label_spans, trial):\n",
        "    # 1) Construct the complete prompt, including all ICEs + query\n",
        "    head = (\"Analyze the sentiment of the last review and respond with \"\n",
        "            \"either positive or negative. Here are several examples.\")\n",
        "    tag  = \"\\nSentiment:\"\n",
        "    demos = list(zip(demo_df[\"sentence\"], demo_df[\"label\"]))\n",
        "    prompt = head + \"\".join(\n",
        "        f\"\\nReview: {s.strip()}{tag}{label_word[l]}\" for s,l in demos\n",
        "    ) + f\"\\nReview: {query['sentence'].strip()}\\nSentiment:\"\n",
        "    enc = tok(prompt, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "    ids, full_mask = enc.input_ids[0], enc.attention_mask[0]\n",
        "\n",
        "    # 2) Pre-calculate clean prediction on the full prompt\n",
        "    pred_b, prob_b = classify_token(ids)\n",
        "    base_ok = (pred_b == (pos_id if query[\"label\"]==1 else neg_id))\n",
        "\n",
        "    # 3) Sequential PGD\n",
        "    # gamma = [1.0]*num_shots\n",
        "    # gamma = [g/sum(gamma) for g in gamma]\n",
        "    gamma = custom_gamma.tolist()\n",
        "    eps_i = [g*eps for g in gamma]\n",
        "    cum_delta = torch.zeros_like(E[ids], device=device)\n",
        "\n",
        "    # Prepare to store per-ICE metrics\n",
        "    metrics_per_ice = []\n",
        "\n",
        "    for i,(_,_,posL) in enumerate(spans):\n",
        "        # mask subsequent ICE_{i+1..n}\n",
        "        mask_i = full_mask.clone()\n",
        "        for j in range(i+1,len(spans)):\n",
        "            s_j,e_j,_ = spans[j]\n",
        "            mask_i[s_j:e_j] = 0\n",
        "            for lp in label_spans[j]:\n",
        "                mask_i[lp] = 0\n",
        "\n",
        "        # 3.1) Local PGD for ICE_i\n",
        "        delta_loc = cum_delta.clone().detach().requires_grad_(True)\n",
        "        for _ in range(steps_local):\n",
        "            emb = E[ids] + delta_loc\n",
        "            logits = model(inputs_embeds=emb.unsqueeze(0),\n",
        "                           attention_mask=mask_i.unsqueeze(0)).logits[0,-1]\n",
        "            tgt_q = pos_id if query[\"label\"]==1 else neg_id\n",
        "            loss = F.cross_entropy(logits.unsqueeze(0),\n",
        "                                   torch.tensor([tgt_q],device=device))\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in posL:\n",
        "                    delta_loc[p] += alpha * delta_loc.grad[p]\n",
        "                span_vec = delta_loc[posL]\n",
        "                norm = span_vec.norm()\n",
        "                if norm > eps_i[i]:\n",
        "                    delta_loc[posL] *= eps_i[i]/norm\n",
        "                delta_loc.grad.zero_()\n",
        "        with torch.no_grad():\n",
        "            for p in posL:\n",
        "                cum_delta[p] = delta_loc[p]\n",
        "\n",
        "        # —— NEW: compute clean_acc_i on ICE_1…ICE_i + query ——\n",
        "        tgt_q = pos_id if query[\"label\"]==1 else neg_id\n",
        "        prefix_prompt = head + \"\".join(\n",
        "            f\"\\nReview: {demos[k][0].strip()}{tag}{label_word[demos[k][1]]}\"\n",
        "            for k in range(i+1)\n",
        "        ) + f\"\\nReview: {query['sentence'].strip()}\\nSentiment:\"\n",
        "        enc_clean = tok(prefix_prompt, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "        ids_clean = enc_clean.input_ids[0]\n",
        "        pred_c, _ = classify_token(ids_clean)\n",
        "        clean_acc_i = 1.0 if pred_c==tgt_q else 0.0\n",
        "\n",
        "        # cumulative word_proj for ICE_1…ICE_i\n",
        "        ids_tmp = ids.clone()\n",
        "        for j in range(i+1):\n",
        "            _,_,posL_j = spans[j]\n",
        "            ids_tmp = word_proj(\n",
        "                ids_tmp,\n",
        "                posL_j,\n",
        "                cum_delta,\n",
        "                eps_i[j],\n",
        "                tgt_q,\n",
        "                full_mask\n",
        "            )\n",
        "        pred_i, _ = classify_token(ids_tmp)\n",
        "        adv_ok_i = (pred_i == tgt_q)\n",
        "\n",
        "        # compute adv_acc_i, drop_i, ASR_i with clamping and correct definition\n",
        "        adv_acc_i = 1.0 if adv_ok_i else 0.0\n",
        "        drop_i    = max(clean_acc_i - adv_acc_i, 0.0)\n",
        "        ASR_i     = 1.0 if (clean_acc_i==1.0 and adv_acc_i==0.0) else 0.0\n",
        "\n",
        "        print(f\"=== ICE {i+1} Metrics === clean_acc: {clean_acc_i:.3f}, adv_acc: {adv_acc_i:.3f}, drop: {drop_i:.3f}, ASR: {ASR_i:.3f}\")\n",
        "\n",
        "        metrics_per_ice.append({\n",
        "            \"clean_acc\": clean_acc_i,\n",
        "            \"adv_acc\":   adv_acc_i,\n",
        "            \"drop\":      drop_i,\n",
        "            \"ASR\":       ASR_i\n",
        "        })\n",
        "\n",
        "    # 4) Final full-word_proj across all spans\n",
        "    ids_adv = ids.clone()\n",
        "    tgt_q   = pos_id if query[\"label\"]==1 else neg_id\n",
        "    for i,(_,_,posL) in enumerate(spans):\n",
        "        ids_adv = word_proj(ids_adv, posL, cum_delta, eps_i[i], tgt_q, full_mask)\n",
        "\n",
        "    # 5) Last-ICE metrics (same definitions)\n",
        "    pred_a, _ = classify_token(ids_adv)\n",
        "    adv_ok    = (pred_a == tgt_q)\n",
        "    clean_acc = 1.0 if base_ok else 0.0\n",
        "    adv_acc   = 1.0 if adv_ok   else 0.0\n",
        "    drop      = max(clean_acc - adv_acc, 0.0)\n",
        "    ASR       = 1.0 if (clean_acc==1.0 and adv_acc==0.0) else 0.0\n",
        "\n",
        "    print(f\"\\n=== Alg2 Trial {trial} Metrics (last ICE) ===\")\n",
        "    print(f\" clean_acc: {clean_acc:.3f}\")\n",
        "    print(f\" adv_acc  : {adv_acc:.3f}\")\n",
        "    print(f\" drop     : {drop:.3f}\")\n",
        "    print(f\" ASR      : {ASR:.3f}\")\n",
        "\n",
        "    # 6) save per-ICE metrics + texts into debug_info pkl\n",
        "    #    AND record the full prompt before and after all perturbations\n",
        "    full_pre  = tok.decode(ids,    skip_special_tokens=True)\n",
        "    full_post = tok.decode(ids_adv, skip_special_tokens=True)\n",
        "\n",
        "    debug_info = {\n",
        "        'trial':      trial,\n",
        "        'full_pre':   full_pre,\n",
        "        'full_post':  full_post,\n",
        "        'ice':        []\n",
        "    }\n",
        "\n",
        "    for i, (s_j, e_j, posL) in enumerate(spans):\n",
        "        sent_pre  = tok.decode(ids[s_j:e_j],     skip_special_tokens=True)\n",
        "        sent_post = tok.decode(ids_adv[s_j:e_j], skip_special_tokens=True)\n",
        "\n",
        "        entry = {\n",
        "            \"ice_index\":      i + 1,\n",
        "            \"pos\":            posL,\n",
        "            \"pre_text\":       tok.decode(ids[posL[0]:posL[-1]+1],     skip_special_tokens=True),\n",
        "            \"post_text\":      tok.decode(ids_adv[posL[0]:posL[-1]+1], skip_special_tokens=True),\n",
        "            \"full_sent_pre\":  sent_pre,\n",
        "            \"full_sent_post\": sent_post,\n",
        "            **metrics_per_ice[i]\n",
        "        }\n",
        "        debug_info[\"ice\"].append(entry)\n",
        "\n",
        "\n",
        "    os.makedirs(\"perturb_info_budget\", exist_ok=True)\n",
        "    with open(f\"perturb_info_budget/alg2_debug_trial_{trial}.pkl\",\"wb\") as f:\n",
        "        pickle.dump(debug_info,f)\n",
        "\n",
        "\n",
        "    if trial == 1:\n",
        "        print(\"=== Full debug_info for trial 1 ===\")\n",
        "        print(debug_info)\n",
        "\n",
        "    return [clean_acc], [adv_acc]\n",
        "\n",
        "# # ─────────────────────────────────────────────────────────────────────────────\n",
        "# # Batch load, run Alg2, and compute averages\n",
        "# # ─────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# Batch load from Alg1 saved PKLs, run Alg2 and collect metrics\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "base2_sum = 0.0\n",
        "adv2_sum  = 0.0\n",
        "all_metrics = []\n",
        "\n",
        "orig_paths = sorted(glob.glob(\"perturb_info/ice_deltas_trial_*.pkl\"))\n",
        "for t, orig_path in enumerate(orig_paths, start=1):\n",
        "\n",
        "    data = pickle.load(open(orig_path, \"rb\"))\n",
        "    demo_df      = pd.DataFrame.from_dict(data[\"demo_df\"])\n",
        "    query        = data[\"query\"]\n",
        "    spans        = data[\"spans\"]\n",
        "    delta_global = torch.tensor(data[\"delta\"], device=device)\n",
        "    label_spans  = data[\"label_spans\"]\n",
        "\n",
        "\n",
        "    b_vec, a_vec = run_alg2_on(demo_df, query, spans, delta_global, label_spans, t)\n",
        "    base2_sum += b_vec[0]\n",
        "    adv2_sum  += a_vec[0]\n",
        "\n",
        "\n",
        "    flat_path = f\"perturb_info_budget/alg2_debug_trial_{t}.pkl\"\n",
        "    flat_data = pickle.load(open(flat_path, \"rb\"))\n",
        "    all_metrics.append(flat_data[\"ice\"])\n",
        "\n",
        "num_trials = len(all_metrics)\n",
        "\n",
        "# overall (last ICE) averages\n",
        "print(\"\\n=== Overall Alg2 (last ICE) ===\")\n",
        "print(f\"Avg clean_acc: {base2_sum/num_trials:.3f}\")\n",
        "print(f\"Avg adv_acc  : {adv2_sum/num_trials:.3f}\")\n",
        "print(f\"Avg drop     : {(base2_sum-adv2_sum)/num_trials:.3f}\")\n",
        "print(f\"Avg ASR      : {1-(adv2_sum/base2_sum) if base2_sum>0 else 0.0:.3f}\")\n",
        "\n",
        "# per-ICE averages\n",
        "print(\"\\n=== Per-ICE Average Metrics Across All Trials ===\")\n",
        "num_ice = len(all_metrics[0])\n",
        "sums = [ {'clean_acc':0,'adv_acc':0,'drop':0,'ASR':0} for _ in range(num_ice) ]\n",
        "for trial_metrics in all_metrics:\n",
        "    for i, m in enumerate(trial_metrics):\n",
        "        sums[i]['clean_acc'] += m['clean_acc']\n",
        "        sums[i]['adv_acc']   += m['adv_acc']\n",
        "        sums[i]['drop']      += m['drop']\n",
        "        sums[i]['ASR']       += m['ASR']\n",
        "for i, s in enumerate(sums, start=1):\n",
        "    print(f\"ICE {i}: clean_acc={s['clean_acc']/num_trials:.3f}, \"\n",
        "          f\"adv_acc={s['adv_acc']/num_trials:.3f}, \"\n",
        "          f\"drop={s['drop']/num_trials:.3f}, \"\n",
        "          f\"ASR={s['ASR']/num_trials:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d416c8ff",
      "metadata": {
        "id": "d416c8ff"
      },
      "outputs": [],
      "source": [
        "#progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5873df67",
      "metadata": {
        "id": "5873df67"
      },
      "outputs": [],
      "source": [
        "import os, glob, pickle, json, numpy as np\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# configuration  – edit here if your paths or constants differ\n",
        "# ------------------------------------------------------------------\n",
        "ALG1_DIR        = \"perturb_info\"          # ice_deltas_trial_*.pkl\n",
        "ALG2_FLAT_DIR   = \"perturb_info_flat\"     # alg2_debug_trial_*.pkl\n",
        "ALG2_BUD_DIR    = \"perturb_info_budget\"   # new budgeted trials\n",
        "DATASET_NAME    = \"sst2\"                  # or read from elsewhere\n",
        "EPSILON         = 100\n",
        "MODEL_NAME      = \"OPT-30b\"\n",
        "N_CONTEXT       = 4                       # num_shots\n",
        "N_EDIT          = 3\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "def mean_or_nan(vals):\n",
        "    return float(np.mean(vals)) if vals else float(\"nan\")\n",
        "\n",
        "def aggregate_alg2(folder):\n",
        "    overall = {\"clean_ACC\": [], \"ADV_ACC\": [], \"ACC_drop\": [], \"ASR\": []}\n",
        "    per_ice = {}      # { \"1\": {...}, ... }\n",
        "\n",
        "    for p in glob.glob(os.path.join(folder, \"alg2_debug_trial_*.pkl\")):\n",
        "        dbg = pickle.load(open(p, \"rb\"))[\"ice\"]       # list per ICE\n",
        "        last = dbg[-1]                                # use last ICE for overall\n",
        "\n",
        "        # overall metrics\n",
        "        overall[\"clean_ACC\"].append(last[\"clean_acc\"])\n",
        "        overall[\"ADV_ACC\"].append(last[\"adv_acc\"])\n",
        "        overall[\"ACC_drop\"].append(last[\"drop\"])\n",
        "        overall[\"ASR\"].append(last[\"ASR\"])\n",
        "\n",
        "        # per-ICE metrics\n",
        "        for entry in dbg:\n",
        "            idx = str(entry[\"ice_index\"])\n",
        "            per_ice.setdefault(idx, {\"clean_ACC\": [], \"ADV_ACC\": [],\n",
        "                                      \"ACC_drop\": [], \"ASR\": []})\n",
        "            per_ice[idx][\"clean_ACC\"].append(entry[\"clean_acc\"])\n",
        "            per_ice[idx][\"ADV_ACC\"].append(entry[\"adv_acc\"])\n",
        "            per_ice[idx][\"ACC_drop\"].append(entry[\"drop\"])\n",
        "            per_ice[idx][\"ASR\"].append(entry[\"ASR\"])\n",
        "\n",
        "    overall_mean = {k: mean_or_nan(v) for k, v in overall.items()}\n",
        "    per_ice_mean = {i: {k: mean_or_nan(v) for k, v in d.items()}\n",
        "                    for i, d in per_ice.items()}\n",
        "    return overall_mean, per_ice_mean\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Alg-1 aggregation\n",
        "# ------------------------------------------------------------------\n",
        "alg1_raw = {\"clean_ACC\": [], \"ADV_ACC\": [], \"ACC_drop\": [], \"ASR\": []}\n",
        "for p in glob.glob(os.path.join(ALG1_DIR, \"ice_deltas_trial_*.pkl\")):\n",
        "    meta = pickle.load(open(p, \"rb\")).get(\"metrics\", {})\n",
        "    for k_csv, k_pkl in [(\"clean_ACC\", \"clean_acc\"),\n",
        "                         (\"ADV_ACC\",   \"adv_acc\"),\n",
        "                         (\"ACC_drop\",  \"drop\"),\n",
        "                         (\"ASR\",       \"ASR\")]:\n",
        "        if k_pkl in meta:\n",
        "            alg1_raw[k_csv].append(meta[k_pkl])\n",
        "alg1_summary = {k: mean_or_nan(v) for k, v in alg1_raw.items()}\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Alg-2-flat & Alg-2-budget aggregation\n",
        "# ------------------------------------------------------------------\n",
        "flat_overall, flat_per_ice   = aggregate_alg2(ALG2_FLAT_DIR)\n",
        "bud_overall,  bud_per_ice    = aggregate_alg2(ALG2_BUD_DIR)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# build final JSON object\n",
        "# ------------------------------------------------------------------\n",
        "summary = {\n",
        "    \"epsilon\": EPSILON,\n",
        "    \"model\":   MODEL_NAME,\n",
        "    \"n\":       N_CONTEXT,\n",
        "    \"alg1\":    alg1_summary,\n",
        "    \"alg2-flat\": {\n",
        "        \"overall\": flat_overall,\n",
        "        \"per_ICE\": flat_per_ice\n",
        "    },\n",
        "    \"alg2-budget\": {\n",
        "        \"overall\": bud_overall,\n",
        "        \"per_ICE\": bud_per_ice\n",
        "    }\n",
        "}\n",
        "\n",
        "# automatic file name\n",
        "json_name = f\"{DATASET_NAME}_{MODEL_NAME.replace(' ','-')}\" \\\n",
        "            f\"_eps{EPSILON}_n{N_CONTEXT}_edit{N_EDIT}.json\"\n",
        "\n",
        "with open(json_name, \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "print(f\"→ written {json_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c81f18ba",
      "metadata": {
        "id": "c81f18ba"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85732b5a",
      "metadata": {
        "id": "85732b5a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91170d6d",
      "metadata": {
        "id": "91170d6d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}